{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "158c4572-66cf-4f94-8f6d-3864c71af573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vanisingh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vanisingh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659f0bc-d56f-42cf-80db-4d279c0d3dfd",
   "metadata": {},
   "source": [
    "### Importing the dataset to train the model on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b64ec-ba14-4703-ac4f-ba23976f04b5",
   "metadata": {},
   "source": [
    "This model is trained on the data in *accountactivity.csv*. This is an accumulation of many credit card statements for the *Date*, *Description*, and *Amount* columns. The transactions were then manually labeled in the *LABEL* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aad60ccb-8b7d-42a6-aca5-e056f94e097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.36</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>THAI SPICE RESTAURAN</td>\n",
       "      <td>51.47</td>\n",
       "      <td>Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>10.44</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>12.63</td>\n",
       "      <td>Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>Target</td>\n",
       "      <td>9.17</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE           DESCRIPTION  AMOUNT           LABEL\n",
       "0  2024-11-29                Amazon    6.36          Retail\n",
       "1  2024-11-28  THAI SPICE RESTAURAN   51.47          Dining\n",
       "2  2024-11-28                Amazon   10.44          Retail\n",
       "3  2024-11-28                  Lyft   12.63  Transportation\n",
       "4  2024-11-27                Target    9.17          Retail"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"accountactivity.csv\"\n",
    "df = pd.read_csv(data_path, encoding='utf-8', encoding_errors='replace')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366f82c-796b-4f42-a091-055015d5b2d0",
   "metadata": {},
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e20c87-a301-4d87-bdec-b119e639e474",
   "metadata": {},
   "source": [
    "remove stopwords and punctuation from the *DESCRIPTION* column to prepare fore text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0567207-dd55-46b0-a994-af929b959ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def text_processing(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize, remove stopwords, and lemmatize\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"DESCRIPTION\"] = df[\"DESCRIPTION\"].apply(text_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e56eed-0d3f-4546-a400-537d1ef24808",
   "metadata": {},
   "source": [
    "### Dropping all columns that do not have a value for LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108548f-6ebd-4cd3-bf39-ce3d30e5a817",
   "metadata": {},
   "source": [
    "Remove all rows that do not have a value for the target column of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "953632f5-72b0-4f50-9584-8097ecccc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"LABEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe08f3-7495-452c-9d38-b2a6cb45f1f8",
   "metadata": {},
   "source": [
    "### Getting value counts for each LABEL category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f0e7a02-5822-4e6a-9b6b-1f66ccdf1983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "Dining            445\n",
       "Other             216\n",
       "Retail            213\n",
       "Grocery           190\n",
       "Gas                67\n",
       "Transportation     62\n",
       "Travel             44\n",
       "Subscription       37\n",
       "Mobility           36\n",
       "Entertainment      26\n",
       "Pharmaceutical     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c7282-152c-46dc-8a84-3ce300316bcb",
   "metadata": {},
   "source": [
    "The output clearly shows that the data is **imbalanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed88d8-33f2-470c-9933-d8e716610d8b",
   "metadata": {},
   "source": [
    "### Getting the data ready for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f62d7c25-0afe-46a3-910a-789528dbc1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {0: 'Dining', 1: 'Entertainment', 2: 'Gas', 3: 'Grocery', 4: 'Mobility', 5: 'Other', 6: 'Pharmaceutical', 7: 'Retail', 8: 'Subscription', 9: 'Transportation', 10: 'Travel'}\n"
     ]
    }
   ],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Encode labels as integers (0 = Retail, 1 = Dining, 2 = Travel)\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"LABEL\"] = label_encoder.fit_transform(df[\"LABEL\"])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Mapping from numeric values to original labels\n",
    "label_mapping = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))\n",
    "\n",
    "print(\"Label mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f475b7e-61be-4a0b-8a7f-99a5dd7f9bfc",
   "metadata": {},
   "source": [
    "### Downloading the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56282f37-7163-4673-91a3-db1cb0d00116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanisingh/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_data(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bf1b2-1539-4eb0-a112-a02004139ca2",
   "metadata": {},
   "source": [
    "### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b16897a-20d0-4a86-91ac-34b71b6d5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df[\"DESCRIPTION\"],\n",
    "                                                  df[\"LABEL\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c411ffc-9735-4448-9426-df1c1dfe916f",
   "metadata": {},
   "source": [
    "### Using SMOTE to oversample under repersented categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99d81bc8-6f66-4147-a529-459e3ad65258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "label_counts = df['LABEL'].value_counts()\n",
    "\n",
    "# Find the label with the maximum frequency\n",
    "max_count = int(label_counts.median())\n",
    "\n",
    "# Initialize an empty DataFrame to hold the oversampled data\n",
    "oversampled_df = pd.DataFrame()\n",
    "\n",
    "# For each label, resample the data to match the maximum count\n",
    "for label, count in label_counts.items():\n",
    "    label_df = df[df['LABEL'] == label]\n",
    "    # If the label has fewer rows, oversample it\n",
    "    if count < max_count:\n",
    "        oversampled_label_df = resample(label_df, \n",
    "                                        replace=True,     # Allow sampling with replacement\n",
    "                                        n_samples=max_count,  # To match the majority class\n",
    "                                        random_state=42)  # For reproducibility\n",
    "        oversampled_df = pd.concat([oversampled_df, oversampled_label_df])\n",
    "    else:\n",
    "        # If the label has more or equal rows, keep it as is\n",
    "        oversampled_df = pd.concat([oversampled_df, label_df])\n",
    "\n",
    "# Shuffling the DataFrame\n",
    "oversampled_df_train = oversampled_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83d57c34-5ef6-4b5b-99d1-67ef2e9077f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = oversampled_df['DESCRIPTION']\n",
    "y_train = oversampled_df['LABEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd9e96b-b043-48c2-913a-4f4533e81838",
   "metadata": {},
   "source": [
    "### Tokenizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010d479-7cee-4124-9142-c7ce2042e2a3",
   "metadata": {},
   "source": [
    "Define a custom PyTorch Dataset class, TransactionDataset, to preprocess and encode textual data and labels for training. It tokenizes input texts, converts labels to tensors, and prepares batched data loaders for training and validation with specified batch sizes and shuffling configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "804c303e-d1dd-48cc-884c-1a788eceecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=32):\n",
    "        self.encodings = tokenize_data(texts, tokenizer, max_length)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b494235-5076-440b-8e6a-8a14ff6ae6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TransactionDataset(X_train.tolist(), y_train, tokenizer)\n",
    "val_dataset = TransactionDataset(X_val.tolist(), y_val, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66a8ed-3a92-4f1c-af13-dd1a2aadafd2",
   "metadata": {},
   "source": [
    "### Loading the model, optimizer and scheduler for learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f776c6b2-b97b-4b55-9780-6fa0fd0cd32a",
   "metadata": {},
   "source": [
    "Used a dynamic learning rate to ensure better convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db2a3b99-0610-4092-bdcb-c6981704c37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_classes)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2dcc9ba-a8e2-4edf-b607-453274578f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanisingh/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548201e0-d86e-41e6-8c02-b5d242179f09",
   "metadata": {},
   "source": [
    "### Defining the train and evaluate function for training BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1424db7-1964-41e7-afa8-d5a09929cd8e",
   "metadata": {},
   "source": [
    "Train the model for a specified number of epochs, computing the training loss and evaluating the model on validation data after each epoch.\n",
    "Log training loss, validation loss, and validation accuracy, saving them into a history DataFrame.\n",
    "Save the model's state after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0bfeeca-7f98-41bf-9971-f08c3d8e6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, epochs, optimizer, scheduler, device):\n",
    "    # Initialize a DataFrame to store losses\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on validation data\n",
    "        val_loss, val_accuracy = evaluate_model(model, val_dataloader, device)\n",
    "\n",
    "        # Log losses\n",
    "        train_loss = total_loss / len(train_dataloader)\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "        print(f\"  Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
    "        print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(val_loss)  # Adjust based on the scheduler type (see below)\n",
    "\n",
    "        epoch_save_path = f\"models/model_epoch_{epoch + 1}.pt\"\n",
    "        torch.save(model.state_dict(), epoch_save_path)\n",
    "        print(f\"  Model saved at: {epoch_save_path}\")\n",
    "\n",
    "    # Convert the history dictionary to a DataFrame\n",
    "    history_df = pd.DataFrame(history)\n",
    "    return history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263e3d5-6f70-405c-97c7-ba08365d5ed0",
   "metadata": {},
   "source": [
    "Evaluate the model on validation data, computing the average loss and accuracy without updating the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "312fb34f-3e78-49b2-ab1f-f633c31c6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Evaluating\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (preds == batch[\"labels\"]).sum().item()\n",
    "            total += batch[\"labels\"].size(0)\n",
    "\n",
    "    avg_loss = val_loss / len(val_dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c56cf-b6af-44d5-b4bd-b9eec7f3a4e8",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7748a3-9065-41d5-897e-b3b3f7a5b4a9",
   "metadata": {},
   "source": [
    "For each epoch, saves the model in a *models* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "575e0ebb-142a-4485-9a64-d31a9844b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|████████████████████████████████████████████▍                                                                     | 58/149 [02:01<03:10,  2.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     15\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Evaluate the model on validation data\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_df = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    epochs=15,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef267802-dc90-47e4-853e-ad283ff5b7a0",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dde01a-cbe7-4a28-ae89-ce371f0d6202",
   "metadata": {},
   "source": [
    "Choose the model associated with the smallest validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c8ccb-cae5-4e39-b3a1-42d80409eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_df[\"epoch\"], history_df[\"train_loss\"], label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(history_df[\"epoch\"], history_df[\"val_loss\"], label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
